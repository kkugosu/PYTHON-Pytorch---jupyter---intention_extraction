{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "new_label = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_label = np.append(new_label,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = torch.zeros(3, 5, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = torch.randn(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    nan,     nan,     nan, -1.1023, -0.7548])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = torch.randn(5)\n",
    "a\n",
    "\n",
    "torch.log(a)\n",
    "tensor([ nan,  nan,  nan,  nan,  nan])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jongsu/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/ipykernel/__main__.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([      -inf, 1.38629436, 1.38629436])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "target = torch.tensor([ 0.,  4.,  4.])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   -inf,  1.3863,  1.3863])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  4,  4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "#import tensorflow as tf\n",
    "\n",
    "import io\n",
    "from gensim.models import word2vec\n",
    "\n",
    "from io import StringIO\n",
    "from pprint import pprint\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import torch.utils.data\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = torch.tensor([[ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.],\n",
    "        [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.],\n",
    "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.],\n",
    "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.],\n",
    "        [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.],\n",
    "        [ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.],\n",
    "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.],\n",
    "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.],\n",
    "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.],\n",
    "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
    "          0.,  0.,  0.,  0.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 28])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "input_v = torch.randn(10,1,100)\n",
    "\n",
    "criterian = nn.MSELoss()\n",
    "\n",
    "class Gru(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Gru, self).__init__()\n",
    "        self.gru = nn.GRU(100,100,bidirectional = True)\n",
    "        self.inh = torch.zeros(2, 1, 100)\n",
    "        self.nn = nn.Linear(200,100)\n",
    "        self.nn2 = nn.Linear(100,28)\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(2, 1, 100)\n",
    "   \n",
    "    def forward(self, sentence):  \n",
    "        output,hidden = gru(sentence,self.inh)\n",
    "        output = self.nn(output.view(10,200))\n",
    "        output2 = self.nn2(output)\n",
    "        return output2,hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gru1 = Gru(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 28])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer1 = optim.SGD(gru1.parameters(), lr=0.1, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.00000e-05 *\n",
      "       5.7007)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while(i < 1000):\n",
    "    i = i + 1\n",
    "    output,_ = gru1(input_v)\n",
    "    loss = criterian(output,a)\n",
    "    optimizer1.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer1.step()\n",
    "    if i == 1000:\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'makesent_gru' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-039bb2d44666>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msent_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmakesent_gru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlast_sent_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_sent_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mGru1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtagset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'makesent_gru' is not defined"
     ]
    }
   ],
   "source": [
    "sent_1 = makesent_gru(100,True).cuda()\n",
    "last_sent_1 = last_sent_net().cuda()\n",
    "Gru1 = Gru(tagset,100).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe0d4121cf0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def argmax(vec):\n",
    "    # return the argmax as a python int\n",
    "    _, idx = torch.max(vec, 1)\n",
    "    return idx.item()\n",
    "\n",
    "\n",
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "\n",
    "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
    "def log_sum_exp(vec):\n",
    "    max_score = vec[0, argmax(vec)]\n",
    "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
    "    return max_score + \\\n",
    "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BiLSTM_CRF(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n",
    "        super(BiLSTM_CRF, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.vocab_size = vocab_size\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        self.tagset_size = len(tag_to_ix)\n",
    "\n",
    "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
    "                            num_layers=1, bidirectional=True)\n",
    "\n",
    "        # Maps the output of the LSTM into tag space.\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
    "\n",
    "        # Matrix of transition parameters.  Entry i,j is the score of\n",
    "        # transitioning *to* i *from* j.\n",
    "        self.transitions = nn.Parameter(\n",
    "            torch.randn(self.tagset_size, self.tagset_size))\n",
    "\n",
    "        # These two statements enforce the constraint that we never transfer\n",
    "        # to the start tag and we never transfer from the stop tag\n",
    "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
    "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
    "\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.randn(2, 1, self.hidden_dim // 2),\n",
    "                torch.randn(2, 1, self.hidden_dim // 2))\n",
    "\n",
    "    def _forward_alg(self, feats):\n",
    "        # Do the forward algorithm to compute the partition function\n",
    "        init_alphas = torch.full((1, self.tagset_size), -10000.)\n",
    "        # START_TAG has all of the score.\n",
    "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
    "\n",
    "        # Wrap in a variable so that we will get automatic backprop\n",
    "        forward_var = init_alphas\n",
    "\n",
    "        # Iterate through the sentence\n",
    "        for feat in feats:\n",
    "            alphas_t = []  # The forward tensors at this timestep\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                # broadcast the emission score: it is the same regardless of\n",
    "                # the previous tag\n",
    "                emit_score = feat[next_tag].view(\n",
    "                    1, -1).expand(1, self.tagset_size)\n",
    "                # the ith entry of trans_score is the score of transitioning to\n",
    "                # next_tag from i\n",
    "                trans_score = self.transitions[next_tag].view(1, -1)\n",
    "                # The ith entry of next_tag_var is the value for the\n",
    "                # edge (i -> next_tag) before we do log-sum-exp\n",
    "                next_tag_var = forward_var + trans_score + emit_score\n",
    "                # The forward variable for this tag is log-sum-exp of all the\n",
    "                # scores.\n",
    "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
    "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        alpha = log_sum_exp(terminal_var)\n",
    "        return alpha\n",
    "\n",
    "    def _get_lstm_features(self, sentence):\n",
    "        self.hidden = self.init_hidden()\n",
    "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
    "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
    "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
    "        lstm_feats = self.hidden2tag(lstm_out)\n",
    "        return lstm_feats\n",
    "\n",
    "    def _score_sentence(self, feats, tags):\n",
    "        # Gives the score of a provided tag sequence\n",
    "        score = torch.zeros(1)\n",
    "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long), tags])\n",
    "        for i, feat in enumerate(feats):\n",
    "            score = score + \\\n",
    "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
    "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
    "        return score\n",
    "\n",
    "    def _viterbi_decode(self, feats):\n",
    "        backpointers = []\n",
    "\n",
    "        # Initialize the viterbi variables in log space\n",
    "        init_vvars = torch.full((1, self.tagset_size), -10000.)\n",
    "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
    "\n",
    "        # forward_var at step i holds the viterbi variables for step i-1\n",
    "        forward_var = init_vvars\n",
    "        for feat in feats:\n",
    "            bptrs_t = []  # holds the backpointers for this step\n",
    "            viterbivars_t = []  # holds the viterbi variables for this step\n",
    "\n",
    "            for next_tag in range(self.tagset_size):\n",
    "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
    "                # previous step, plus the score of transitioning\n",
    "                # from tag i to next_tag.\n",
    "                # We don't include the emission scores here because the max\n",
    "                # does not depend on them (we add them in below)\n",
    "                next_tag_var = forward_var + self.transitions[next_tag]\n",
    "                best_tag_id = argmax(next_tag_var)\n",
    "                bptrs_t.append(best_tag_id)\n",
    "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
    "            # Now add in the emission scores, and assign forward_var to the set\n",
    "            # of viterbi variables we just computed\n",
    "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
    "            backpointers.append(bptrs_t)\n",
    "\n",
    "        # Transition to STOP_TAG\n",
    "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        best_tag_id = argmax(terminal_var)\n",
    "        path_score = terminal_var[0][best_tag_id]\n",
    "\n",
    "        # Follow the back pointers to decode the best path.\n",
    "        best_path = [best_tag_id]\n",
    "        for bptrs_t in reversed(backpointers):\n",
    "            best_tag_id = bptrs_t[best_tag_id]\n",
    "            best_path.append(best_tag_id)\n",
    "        # Pop off the start tag (we dont want to return that to the caller)\n",
    "        start = best_path.pop()\n",
    "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
    "        best_path.reverse()\n",
    "        return path_score, best_path\n",
    "\n",
    "    def neg_log_likelihood(self, sentence, tags):\n",
    "        feats = self._get_lstm_features(sentence)\n",
    "        forward_score = self._forward_alg(feats)\n",
    "        gold_score = self._score_sentence(feats, tags)\n",
    "        return forward_score - gold_score\n",
    "\n",
    "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
    "        # Get the emission scores from the BiLSTM\n",
    "        lstm_feats = self._get_lstm_features(sentence)\n",
    "\n",
    "        # Find the best path, given the features.\n",
    "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
    "        return score, tag_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B', 'I', 'O', 'O', 'O', 'O', 'B']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_to_ix[STOP_TAG]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(9.2679), [1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])\n",
      "tensor([ 0.4140])\n",
      "tensor([ 12.1252])\n",
      "tensor([ 6.4185])\n",
      "tensor([ 12.1535])\n",
      "tensor([ 6.2530])\n",
      "tensor([ 12.1136])\n",
      "tensor([ 6.1449])\n",
      "tensor([ 11.6606])\n",
      "tensor([ 5.9908])\n",
      "tensor([ 11.7309])\n",
      "tensor([ 6.1294])\n",
      "tensor([ 11.5203])\n",
      "tensor([ 5.7167])\n",
      "tensor([ 11.4807])\n",
      "tensor([ 5.9719])\n",
      "tensor([ 11.1596])\n",
      "tensor([ 5.7693])\n",
      "tensor([ 11.1812])\n",
      "tensor([ 5.9796])\n",
      "tensor([ 10.9413])\n",
      "tensor([ 5.8421])\n",
      "tensor([ 10.9456])\n",
      "tensor([ 5.5421])\n",
      "tensor([ 10.9473])\n",
      "tensor([ 5.8403])\n",
      "tensor([ 10.7281])\n",
      "tensor([ 5.5389])\n",
      "tensor([ 10.4887])\n",
      "tensor([ 5.5332])\n",
      "tensor([ 10.3875])\n",
      "tensor([ 5.5609])\n",
      "tensor([ 10.1276])\n",
      "tensor([ 5.6570])\n",
      "tensor([ 10.1859])\n",
      "tensor([ 5.2119])\n",
      "tensor([ 9.9699])\n",
      "tensor([ 5.2201])\n",
      "tensor([ 10.0854])\n",
      "tensor([ 5.6123])\n",
      "tensor([ 9.7510])\n",
      "tensor([ 5.5170])\n",
      "tensor([ 9.7477])\n",
      "tensor([ 5.1390])\n",
      "tensor([ 9.8829])\n",
      "tensor([ 5.1448])\n",
      "tensor([ 9.7941])\n",
      "tensor([ 4.9904])\n",
      "tensor([ 9.5157])\n",
      "tensor([ 5.2309])\n",
      "tensor([ 9.4689])\n",
      "tensor([ 4.8448])\n",
      "tensor([ 9.5186])\n",
      "tensor([ 4.9510])\n",
      "tensor([ 9.5698])\n",
      "tensor([ 4.9223])\n",
      "tensor([ 9.2297])\n",
      "tensor([ 4.7118])\n",
      "tensor([ 9.1265])\n",
      "tensor([ 4.6763])\n",
      "tensor([ 8.9981])\n",
      "tensor([ 4.7453])\n",
      "tensor([ 8.9728])\n",
      "tensor([ 4.6053])\n",
      "tensor([ 8.9466])\n",
      "tensor([ 4.7839])\n",
      "tensor([ 8.7679])\n",
      "tensor([ 5.2122])\n",
      "tensor([ 8.9760])\n",
      "tensor([ 4.5978])\n",
      "tensor([ 8.6688])\n",
      "tensor([ 4.3746])\n",
      "tensor([ 8.6508])\n",
      "tensor([ 4.8004])\n",
      "tensor([ 8.4273])\n",
      "tensor([ 4.5365])\n",
      "tensor([ 8.7982])\n",
      "tensor([ 4.3975])\n",
      "tensor([ 8.5770])\n",
      "tensor([ 4.3477])\n",
      "tensor([ 8.5458])\n",
      "tensor([ 4.3241])\n",
      "tensor([ 8.4353])\n",
      "tensor([ 4.5619])\n",
      "tensor([ 8.3948])\n",
      "tensor([ 4.2551])\n",
      "tensor([ 8.3578])\n",
      "tensor([ 4.3726])\n",
      "tensor([ 8.1370])\n",
      "tensor([ 4.2461])\n",
      "tensor([ 8.2079])\n",
      "tensor([ 4.7795])\n",
      "tensor([ 8.0740])\n",
      "tensor([ 4.5162])\n",
      "tensor([ 8.1919])\n",
      "tensor([ 4.4553])\n",
      "tensor([ 7.7565])\n",
      "tensor([ 4.4739])\n",
      "tensor([ 7.7087])\n",
      "tensor([ 4.2045])\n",
      "tensor([ 8.0725])\n",
      "tensor([ 3.9714])\n",
      "tensor([ 7.6741])\n",
      "tensor([ 4.1529])\n",
      "tensor([ 7.9384])\n",
      "tensor([ 3.9441])\n",
      "tensor([ 7.7695])\n",
      "tensor([ 3.8368])\n",
      "tensor([ 7.8490])\n",
      "tensor([ 3.9799])\n",
      "tensor([ 7.4294])\n",
      "tensor([ 3.8133])\n",
      "tensor([ 7.4308])\n",
      "tensor([ 3.8320])\n",
      "tensor([ 7.6587])\n",
      "tensor([ 3.8982])\n",
      "tensor([ 7.4088])\n",
      "tensor([ 4.1206])\n",
      "tensor([ 7.6341])\n",
      "tensor([ 3.7745])\n",
      "tensor([ 7.2851])\n",
      "tensor([ 3.5842])\n",
      "tensor([ 7.2647])\n",
      "tensor([ 4.3268])\n",
      "tensor([ 7.1526])\n",
      "tensor([ 3.8504])\n",
      "tensor([ 7.3193])\n",
      "tensor([ 3.5042])\n",
      "tensor([ 7.2967])\n",
      "tensor([ 3.4734])\n",
      "tensor([ 7.1351])\n",
      "tensor([ 3.7165])\n",
      "tensor([ 7.1976])\n",
      "tensor([ 3.7039])\n",
      "tensor([ 7.1549])\n",
      "tensor([ 3.3984])\n",
      "tensor([ 7.1359])\n",
      "tensor([ 3.2226])\n",
      "tensor([ 7.0658])\n",
      "tensor([ 3.6752])\n",
      "tensor([ 6.5833])\n",
      "tensor([ 3.3897])\n",
      "tensor([ 6.6745])\n",
      "tensor([ 3.1308])\n",
      "tensor([ 6.9026])\n",
      "tensor([ 3.3394])\n",
      "tensor([ 6.7174])\n",
      "tensor([ 3.4368])\n",
      "tensor([ 6.8131])\n",
      "tensor([ 3.3539])\n",
      "tensor([ 6.6650])\n",
      "tensor([ 2.9167])\n",
      "tensor([ 6.8067])\n",
      "tensor([ 3.3845])\n",
      "tensor([ 6.5391])\n",
      "tensor([ 3.1390])\n",
      "tensor([ 6.6507])\n",
      "tensor([ 3.0213])\n",
      "tensor([ 6.6109])\n",
      "tensor([ 3.3617])\n",
      "tensor([ 6.8383])\n",
      "tensor([ 2.9552])\n",
      "tensor([ 6.5238])\n",
      "tensor([ 2.9554])\n",
      "tensor([ 6.3291])\n",
      "tensor([ 3.3144])\n",
      "tensor([ 6.1463])\n",
      "tensor([ 2.9069])\n",
      "tensor([ 6.0761])\n",
      "tensor([ 3.1386])\n",
      "tensor([ 5.9671])\n",
      "tensor([ 3.1566])\n",
      "tensor([ 6.3085])\n",
      "tensor([ 3.0739])\n",
      "tensor([ 6.0782])\n",
      "tensor([ 2.8808])\n",
      "tensor([ 5.9040])\n",
      "tensor([ 2.7405])\n",
      "tensor([ 6.2331])\n",
      "tensor([ 2.6770])\n",
      "tensor([ 5.8029])\n",
      "tensor([ 2.7182])\n",
      "tensor([ 6.4105])\n",
      "tensor([ 2.6714])\n",
      "tensor([ 6.2242])\n",
      "tensor([ 2.6515])\n",
      "tensor([ 5.9152])\n",
      "tensor([ 2.7993])\n",
      "tensor([ 5.8748])\n",
      "tensor([ 3.2095])\n",
      "tensor([ 5.8168])\n",
      "tensor([ 2.6710])\n",
      "tensor([ 5.5525])\n",
      "tensor([ 2.4924])\n",
      "tensor([ 5.5827])\n",
      "tensor([ 2.4215])\n",
      "tensor([ 5.7426])\n",
      "tensor([ 2.4040])\n",
      "tensor([ 5.5332])\n",
      "tensor([ 2.5239])\n",
      "tensor([ 5.5858])\n",
      "tensor([ 2.3369])\n",
      "tensor([ 5.9829])\n",
      "tensor([ 2.5373])\n",
      "tensor([ 5.3313])\n",
      "tensor([ 2.4382])\n",
      "tensor([ 5.2006])\n",
      "tensor([ 2.4455])\n",
      "tensor([ 5.5648])\n",
      "tensor([ 2.4292])\n",
      "tensor([ 5.2366])\n",
      "tensor([ 2.6507])\n",
      "tensor([ 5.5453])\n",
      "tensor([ 2.2816])\n",
      "tensor([ 5.4189])\n",
      "tensor([ 2.0109])\n",
      "tensor([ 5.2907])\n",
      "tensor([ 2.1068])\n",
      "tensor([ 4.9361])\n",
      "tensor([ 2.2720])\n",
      "tensor([ 4.9944])\n",
      "tensor([ 2.2927])\n",
      "tensor([ 5.0934])\n",
      "tensor([ 2.0188])\n",
      "tensor([ 5.3807])\n",
      "tensor([ 2.0395])\n",
      "tensor([ 4.5279])\n",
      "tensor([ 2.1843])\n",
      "tensor([ 5.4159])\n",
      "tensor([ 2.3519])\n",
      "tensor([ 4.9631])\n",
      "tensor([ 1.8997])\n",
      "tensor([ 5.0213])\n",
      "tensor([ 2.5785])\n",
      "tensor([ 4.8745])\n",
      "tensor([ 1.9689])\n",
      "tensor([ 5.2105])\n",
      "tensor([ 2.0347])\n",
      "tensor([ 4.9975])\n",
      "tensor([ 2.5039])\n",
      "tensor([ 4.7342])\n",
      "tensor([ 1.9495])\n",
      "tensor([ 4.4897])\n",
      "tensor([ 1.8957])\n",
      "tensor([ 4.8529])\n",
      "tensor([ 1.7351])\n",
      "tensor([ 4.5206])\n",
      "tensor([ 1.7422])\n",
      "tensor([ 5.1107])\n",
      "tensor([ 2.1224])\n",
      "tensor([ 4.1098])\n",
      "tensor([ 1.9392])\n",
      "tensor([ 4.9471])\n",
      "tensor([ 1.7557])\n",
      "tensor([ 4.5250])\n",
      "tensor([ 1.7832])\n",
      "tensor([ 4.3077])\n",
      "tensor([ 1.9878])\n",
      "tensor([ 4.1392])\n",
      "tensor([ 1.8360])\n",
      "tensor([ 4.3839])\n",
      "tensor([ 1.7903])\n",
      "tensor([ 4.0431])\n",
      "tensor([ 1.7191])\n",
      "tensor([ 4.0574])\n",
      "tensor([ 1.7261])\n",
      "tensor([ 3.8015])\n",
      "tensor([ 1.6818])\n",
      "tensor([ 4.5376])\n",
      "tensor([ 1.9202])\n",
      "tensor([ 4.5465])\n",
      "tensor([ 1.6439])\n",
      "tensor([ 3.8306])\n",
      "tensor([ 1.5268])\n",
      "tensor([ 4.3984])\n",
      "tensor([ 1.8938])\n",
      "tensor([ 3.7725])\n",
      "tensor([ 1.5483])\n",
      "tensor([ 3.7821])\n",
      "tensor([ 2.4868])\n",
      "tensor([ 3.8342])\n",
      "tensor([ 1.5051])\n",
      "tensor([ 3.5446])\n",
      "tensor([ 1.5128])\n",
      "tensor([ 3.9371])\n",
      "tensor([ 1.4575])\n",
      "tensor([ 3.4875])\n",
      "tensor([ 1.4014])\n",
      "tensor([ 3.9864])\n",
      "tensor([ 1.6188])\n",
      "tensor([ 3.5322])\n",
      "tensor([ 1.2011])\n",
      "tensor([ 3.6465])\n",
      "tensor([ 1.3301])\n",
      "tensor([ 3.4666])\n",
      "tensor([ 1.2637])\n",
      "tensor([ 3.2282])\n",
      "tensor([ 1.2406])\n",
      "tensor([ 3.2113])\n",
      "tensor([ 1.3682])\n",
      "tensor([ 3.3377])\n",
      "tensor([ 1.4565])\n",
      "tensor([ 3.3106])\n",
      "tensor([ 1.1205])\n",
      "tensor([ 3.3622])\n",
      "tensor([ 1.2099])\n",
      "tensor([ 3.1414])\n",
      "tensor([ 1.1696])\n",
      "tensor([ 3.7087])\n",
      "tensor([ 1.1787])\n",
      "tensor([ 4.0067])\n",
      "tensor([ 1.6253])\n",
      "tensor([ 3.0515])\n",
      "tensor([ 1.4310])\n",
      "tensor([ 3.1544])\n",
      "tensor([ 1.1096])\n",
      "tensor([ 3.2310])\n",
      "tensor([ 1.1602])\n",
      "tensor([ 3.1173])\n",
      "tensor([ 1.0947])\n",
      "tensor([ 3.7422])\n",
      "tensor([ 1.5247])\n",
      "tensor([ 3.2013])\n",
      "tensor([ 1.3918])\n",
      "tensor([ 3.1394])\n",
      "tensor([ 1.0312])\n",
      "tensor([ 3.3962])\n",
      "tensor([ 1.0067])\n",
      "tensor([ 2.6988])\n",
      "tensor([ 1.3302])\n",
      "tensor([ 2.9762])\n",
      "tensor([ 1.0200])\n",
      "tensor([ 2.9578])\n",
      "tensor([ 0.9439])\n",
      "tensor([ 2.7946])\n",
      "tensor([ 1.1054])\n",
      "tensor([ 3.0293])\n",
      "tensor([ 0.9993])\n",
      "tensor([ 2.8375])\n",
      "tensor([ 0.9728])\n",
      "tensor([ 2.7521])\n",
      "tensor([ 1.3580])\n",
      "tensor([ 2.7927])\n",
      "tensor([ 2.0344])\n",
      "tensor([ 2.5696])\n",
      "tensor([ 1.1576])\n",
      "tensor([ 2.5633])\n",
      "tensor([ 1.5481])\n",
      "tensor([ 2.5920])\n",
      "tensor([ 1.3889])\n",
      "tensor([ 2.6270])\n",
      "tensor([ 0.7807])\n",
      "tensor([ 2.4850])\n",
      "tensor([ 0.8529])\n",
      "tensor([ 2.3161])\n",
      "tensor([ 0.8978])\n",
      "tensor([ 2.3123])\n",
      "tensor([ 0.9530])\n",
      "tensor([ 2.8119])\n",
      "tensor([ 0.8117])\n",
      "tensor([ 2.5919])\n",
      "tensor([ 0.7761])\n",
      "tensor([ 2.7004])\n",
      "tensor([ 0.9629])\n",
      "tensor([ 2.2568])\n",
      "tensor([ 0.7796])\n",
      "tensor([ 2.4820])\n",
      "tensor([ 0.8817])\n",
      "tensor([ 2.6853])\n",
      "tensor([ 0.7809])\n",
      "tensor([ 2.3830])\n",
      "tensor([ 1.1183])\n",
      "tensor([ 2.1903])\n",
      "tensor([ 0.9591])\n",
      "tensor([ 2.2244])\n",
      "tensor([ 1.0840])\n",
      "tensor([ 2.2648])\n",
      "tensor([ 1.0573])\n",
      "tensor([ 2.0452])\n",
      "tensor([ 0.7569])\n",
      "tensor([ 2.1278])\n",
      "tensor([ 0.7279])\n",
      "tensor([ 2.1779])\n",
      "tensor([ 0.8292])\n",
      "tensor([ 2.0420])\n",
      "tensor([ 0.9741])\n",
      "tensor([ 2.0229])\n",
      "tensor([ 0.6206])\n",
      "tensor([ 2.5870])\n",
      "tensor([ 0.8660])\n",
      "tensor([ 2.0594])\n",
      "tensor([ 0.7903])\n",
      "tensor([ 1.8952])\n",
      "tensor([ 0.6448])\n",
      "tensor([ 1.9827])\n",
      "tensor([ 0.9251])\n",
      "tensor([ 2.0168])\n",
      "tensor([ 0.7537])\n",
      "tensor([ 2.3939])\n",
      "tensor([ 0.5863])\n",
      "tensor([ 2.3761])\n",
      "tensor([ 0.6491])\n",
      "tensor([ 2.0810])\n",
      "tensor([ 0.7558])\n",
      "tensor([ 2.2477])\n",
      "tensor([ 1.1660])\n",
      "tensor([ 1.8102])\n",
      "tensor([ 0.5833])\n",
      "tensor([ 1.9121])\n",
      "tensor([ 0.6687])\n",
      "tensor([ 1.8587])\n",
      "tensor([ 0.6151])\n",
      "tensor([ 1.6832])\n",
      "tensor([ 0.5960])\n",
      "tensor([ 2.1290])\n",
      "tensor([ 0.9553])\n",
      "tensor([ 1.8122])\n",
      "tensor([ 0.5854])\n",
      "tensor([ 1.7701])\n",
      "tensor([ 0.6137])\n",
      "tensor([ 1.7141])\n",
      "tensor([ 0.7604])\n",
      "tensor([ 1.6793])\n",
      "tensor([ 0.7114])\n",
      "tensor([ 1.7181])\n",
      "tensor([ 0.5805])\n",
      "tensor([ 1.6775])\n",
      "tensor([ 0.5371])\n",
      "tensor([ 1.5659])\n",
      "tensor([ 0.5796])\n",
      "tensor([ 1.7077])\n",
      "tensor([ 0.6144])\n",
      "tensor([ 1.5749])\n",
      "tensor([ 0.6278])\n",
      "tensor([ 1.8756])\n",
      "tensor([ 0.5266])\n",
      "tensor([ 1.6030])\n",
      "tensor([ 0.5252])\n",
      "tensor([ 1.5449])\n",
      "tensor([ 0.7025])\n",
      "tensor([ 1.5736])\n",
      "tensor([ 0.8168])\n",
      "tensor([ 1.6233])\n",
      "tensor([ 0.5059])\n",
      "tensor([ 1.5714])\n",
      "tensor([ 0.4813])\n",
      "tensor([ 1.5080])\n",
      "tensor([ 0.6096])\n",
      "tensor([ 1.5588])\n",
      "tensor([ 0.5322])\n",
      "tensor([ 1.6953])\n",
      "tensor([ 0.5297])\n",
      "tensor([ 1.4272])\n",
      "tensor([ 0.4739])\n",
      "tensor([ 1.7704])\n",
      "tensor([ 0.5736])\n",
      "tensor([ 1.7917])\n",
      "tensor([ 0.5332])\n",
      "tensor([ 1.9734])\n",
      "tensor([ 0.4547])\n",
      "tensor([ 1.4057])\n",
      "tensor([ 0.4379])\n",
      "tensor([ 1.4281])\n",
      "tensor([ 0.4688])\n",
      "tensor([ 1.3283])\n",
      "tensor([ 0.4027])\n",
      "tensor([ 1.5912])\n",
      "tensor([ 0.5628])\n",
      "tensor([ 1.3709])\n",
      "tensor([ 0.4709])\n",
      "tensor([ 1.3944])\n",
      "tensor([ 0.5562])\n",
      "tensor([ 1.4006])\n",
      "tensor([ 0.4257])\n",
      "tensor([ 2.1293])\n",
      "tensor([ 0.4998])\n",
      "tensor([ 1.2933])\n",
      "tensor([ 0.4938])\n",
      "tensor([ 1.3386])\n",
      "tensor([ 0.6257])\n",
      "tensor([ 1.2691])\n",
      "tensor([ 0.4099])\n",
      "tensor([ 1.3018])\n",
      "tensor([ 0.4637])\n",
      "tensor([ 1.3003])\n",
      "tensor([ 0.4737])\n",
      "tensor([ 1.3034])\n",
      "tensor([ 0.4064])\n",
      "tensor([ 1.2986])\n",
      "tensor([ 0.5365])\n",
      "tensor([ 1.2166])\n",
      "tensor([ 0.3936])\n",
      "tensor([ 1.3099])\n",
      "tensor([ 1.9355])\n",
      "tensor([ 1.2774])\n",
      "tensor([ 0.4140])\n",
      "tensor([ 1.1722])\n",
      "tensor([ 0.4252])\n",
      "tensor([ 1.2500])\n",
      "tensor([ 0.4490])\n",
      "tensor([ 1.2418])\n",
      "tensor([ 0.3715])\n",
      "tensor([ 1.5881])\n",
      "tensor([ 0.3314])\n",
      "tensor([ 1.3897])\n",
      "tensor([ 0.3990])\n",
      "tensor([ 1.1338])\n",
      "tensor([ 0.3480])\n",
      "tensor([ 1.2159])\n",
      "tensor([ 0.3515])\n",
      "tensor([ 1.1383])\n",
      "tensor([ 0.5168])\n",
      "tensor([ 1.3605])\n",
      "tensor([ 0.3786])\n",
      "tensor([ 1.0485])\n",
      "tensor([ 0.3651])\n",
      "tensor([ 1.0289])\n",
      "tensor([ 0.3844])\n",
      "tensor([ 1.1643])\n",
      "tensor([ 0.4260])\n",
      "tensor([ 1.4665])\n",
      "tensor([ 0.4070])\n",
      "tensor([ 1.0606])\n",
      "tensor([ 0.3266])\n",
      "tensor([ 1.0587])\n",
      "tensor([ 0.3084])\n",
      "tensor([ 1.1142])\n",
      "tensor([ 0.4176])\n",
      "tensor([ 1.1013])\n",
      "tensor([ 0.5308])\n",
      "tensor([ 1.3301])\n",
      "tensor([ 0.3462])\n",
      "tensor([ 1.1320])\n",
      "tensor([ 0.3360])\n",
      "tensor([ 1.1594])\n",
      "tensor([ 0.3115])\n",
      "tensor([ 1.1831])\n",
      "tensor([ 0.4722])\n",
      "tensor([ 1.0238])\n",
      "tensor([ 0.4001])\n",
      "tensor([ 1.0378])\n",
      "tensor([ 0.4230])\n",
      "tensor([ 1.0189])\n",
      "tensor([ 0.4143])\n",
      "tensor([ 1.0148])\n",
      "tensor([ 0.3429])\n",
      "tensor([ 1.1704])\n",
      "tensor([ 0.3718])\n",
      "tensor([ 0.9683])\n",
      "tensor([ 0.3366])\n",
      "tensor([ 0.9768])\n",
      "tensor([ 0.3276])\n",
      "tensor([ 1.2299])\n",
      "tensor([ 0.4097])\n",
      "tensor([ 0.9971])\n",
      "tensor([ 0.3469])\n",
      "tensor([ 0.9290])\n",
      "tensor([ 0.3164])\n",
      "tensor([ 0.9398])\n",
      "tensor([ 0.3187])\n",
      "tensor([ 1.0193])\n",
      "tensor([ 0.3636])\n",
      "tensor([ 0.9624])\n",
      "tensor([ 0.4211])\n",
      "tensor([ 0.8988])\n",
      "tensor([ 0.5434])\n",
      "tensor([ 0.9757])\n",
      "tensor([ 0.2915])\n",
      "tensor([ 1.1268])\n",
      "tensor([ 0.3121])\n",
      "tensor([ 1.0243])\n",
      "tensor([ 0.3504])\n",
      "tensor([ 1.0730])\n",
      "tensor([ 0.3181])\n",
      "tensor([ 1.0463])\n",
      "tensor([ 0.2655])\n",
      "tensor([ 1.0119])\n",
      "tensor([ 0.3041])\n",
      "tensor([ 0.8756])\n",
      "tensor([ 0.6524])\n",
      "tensor([ 1.1624])\n",
      "tensor([ 0.2808])\n",
      "tensor([ 0.8994])\n",
      "tensor([ 0.3951])\n",
      "tensor([ 0.9226])\n",
      "tensor([ 0.2930])\n",
      "tensor([ 1.0646])\n",
      "tensor([ 0.3937])\n",
      "tensor([ 0.9709])\n",
      "tensor([ 0.2644])\n",
      "tensor([ 0.9833])\n",
      "tensor([ 0.2893])\n",
      "tensor([ 0.8247])\n",
      "tensor([ 0.3747])\n",
      "tensor([ 0.8704])\n",
      "tensor([ 0.2920])\n",
      "tensor([ 0.8535])\n",
      "tensor([ 0.2999])\n",
      "tensor([ 0.9226])\n",
      "tensor([ 0.3842])\n",
      "tensor([ 0.8729])\n",
      "(tensor(25.6223), [0, 1, 1, 1, 2, 2, 2, 0, 1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "START_TAG = \"<START>\"\n",
    "STOP_TAG = \"<STOP>\"\n",
    "EMBEDDING_DIM = 5\n",
    "HIDDEN_DIM = 4\n",
    "\n",
    "# Make up some training data\n",
    "training_data = [(\n",
    "    \"the wall street journal reported today that apple corporation made money\".split(),\n",
    "    \"B I I I O O O B I O O\".split()\n",
    "), (\n",
    "    \"georgia tech is a university in georgia\".split(),\n",
    "    \"B I O O O O B\".split()\n",
    ")]\n",
    "\n",
    "word_to_ix = {}\n",
    "for sentence, tags in training_data:\n",
    "    for word in sentence:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "\n",
    "tag_to_ix = {\"B\": 0, \"I\": 1, \"O\": 2, START_TAG: 3, STOP_TAG: 4}\n",
    "\n",
    "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "\n",
    "# Check predictions before training\n",
    "with torch.no_grad():\n",
    "    precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    precheck_tags = torch.tensor([tag_to_ix[t] for t in training_data[0][1]], dtype=torch.long)\n",
    "    print(model(precheck_sent))\n",
    "\n",
    "# Make sure prepare_sequence from earlier in the LSTM section is loaded\n",
    "for epoch in range(\n",
    "        300):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    for sentence, tags in training_data:\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is,\n",
    "        # turn them into Tensors of word indices.\n",
    "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        targets = torch.tensor([tag_to_ix[t] for t in tags], dtype=torch.long)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        print(loss)\n",
    "        loss = model.neg_log_likelihood(sentence_in, targets)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        # calling optimizer.step()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Check predictions after training\n",
    "with torch.no_grad():\n",
    "    precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    print(model(precheck_sent))\n",
    "# We got it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-4.2.0]",
   "language": "python",
   "name": "conda-env-anaconda3-4.2.0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
